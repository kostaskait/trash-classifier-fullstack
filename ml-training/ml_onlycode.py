# ==========================================================
# Trash Classification â€” EfficientNetB0 + MixUp + Fine-tuning
# Split ÏƒÎµ train/val/test, MixUp, 2-ÏƒÏ„Î¬Î´Î¹Î± training, TTA Î±Î¾Î¹Î¿Î»ÏŒÎ³Î·ÏƒÎ·,
# Î±Ï€Î¿Î¸Î®ÎºÎµÏ…ÏƒÎ· ÏƒÎµ .keras ÎºÎ±Î¹ TFLite (FP16/INT8) Î¼Îµ "ÏƒÎ¹Ï‰Ï€Î·Î»Î®" Î¼ÎµÏ„Î±Ï„ÏÎ¿Ï€Î®.
# ==========================================================

# ----------------------------- [LOG/WARNINGS] -----------------------------
# Î’Î¬Î¶Î¿Ï…Î¼Îµ Î±Ï…Ï„Î¬ Î Î¡Î™Î Î±Ï€ÏŒ Ï„Î¿ import tensorflow Î³Î¹Î± Î½Î± Î¹ÏƒÏ‡ÏÏƒÎ¿Ï…Î½ Ï€Î±Î½Ï„Î¿Ï.
import os, warnings, io, contextlib  # io/contextlib Î³Î¹Î± "ÏƒÎ¯Î³Î±ÏƒÎ·" stdout/stderr

os.environ["TF_CPP_MIN_LOG_LEVEL"] = "3"  # 1: ÎºÏÏÎ²ÎµÎ¹ INFO, 2: +WARNING, 3: +ERROR (Î±Ï€ÏŒ TF C++ backend)

# Î¦Î¹Î»Ï„ÏÎ¬ÏÎ¿Ï…Î¼Îµ Î¼ÎµÏÎ¹ÎºÎ¬ ÏƒÏ…Î½Î®Î¸Î· Ï€ÏÎ¿ÎµÎ¹Î´Î¿Ï€Î¿Î¹Î·Ï„Î¹ÎºÎ¬ Î¼Î·Î½ÏÎ¼Î±Ï„Î± Ï€Î¿Ï… Î´ÎµÎ½ Î¼Î±Ï‚ Î±Ï†Î¿ÏÎ¿ÏÎ½
warnings.filterwarnings("ignore", message=r"Your `PyDataset` class.*")  # Î±Ï€ÏŒ Keras data adapters
warnings.filterwarnings("ignore", message=r"This ImageDataGenerator specifies `featurewise_center`.*")  # legacy Ï€ÏÎ¿ÎµÎ¹Î´Î¿Ï€Î¿Î¯Î·ÏƒÎ·
warnings.filterwarnings("ignore", message=r"Glyph .* missing from current font")  # matplotlib glyph warning
warnings.filterwarnings("ignore", message=r".*quantized inputs were expected.*")  # TFLite INT8 generic warning
# -------------------------------------------------------------------------


# ----------------------------- [IMPORTS / SEEDS] --------------------------
import random, shutil, glob, math, json, pathlib   # Ï„Ï…Ï€Î¹ÎºÎ¬ utilities
import numpy as np                                  # Î±ÏÎ¹Î¸Î¼Î·Ï„Î¹ÎºÎ¬
import matplotlib.pyplot as plt                     # Î³ÏÎ±Ï†Î®Î¼Î±Ï„Î±
import tensorflow as tf                             # TF/Keras
from tensorflow.keras import layers, models, regularizers
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.applications import EfficientNetB0
from tensorflow.keras.applications.efficientnet import preprocess_input
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint
from sklearn.metrics import classification_report, f1_score, confusion_matrix, ConfusionMatrixDisplay
from PIL import Image

tf.get_logger().setLevel("ERROR")  # Î¼ÏŒÎ½Î¿ ERROR Î±Ï€ÏŒ Ï„Î¿Î½ Python logger Ï„Î¿Ï… TF (Î»Î¹Î³ÏŒÏ„ÎµÏÎ· Ï†Î»Ï…Î±ÏÎ¯Î±)

SEED = 42
random.seed(SEED); np.random.seed(SEED); tf.random.set_seed(SEED)  # ÏƒÏ„Î±Î¸ÎµÏÎ¬ Î±Ï€Î¿Ï„ÎµÎ»Î­ÏƒÎ¼Î±Ï„Î± ÏŒÏ€Î¿Ï… Î³Î¯Î½ÎµÏ„Î±Î¹
# -------------------------------------------------------------------------


# ----------------------------- [HELPERS Î“Î™Î‘ "Î£Î™Î©Î Î—"] ----------------------
@contextlib.contextmanager
def suppress_tf_io():
    """ÎšÏÏÎ²ÎµÎ¹ stdout/stderr ÎœÎŸÎÎŸ Î¼Î­ÏƒÎ± ÏƒÏ„Î¿ with-block (Î³Î¹Î± save/convert)."""
    buf_out, buf_err = io.StringIO(), io.StringIO()       # Ï€ÏÎ¿ÏƒÏ‰ÏÎ¹Î½Î¬ buffers
    with contextlib.redirect_stdout(buf_out), contextlib.redirect_stderr(buf_err):
        yield                                             # ÏŒ,Ï„Î¹ Ï„ÏÎ­Ï‡ÎµÎ¹ Î¼Î­ÏƒÎ±, Î´ÎµÎ½ Ï„Ï…Ï€ÏÎ½ÎµÎ¹ ÏƒÏ„Î¿ output

def save_tflite_quiet(converter: tf.lite.TFLiteConverter, out_path: str):
    """ÎœÎµÏ„Î±Ï„ÏÎ­Ï€ÎµÎ¹ ÏƒÎµ .tflite Ï‡Ï‰ÏÎ¯Ï‚ Î½Î± Î³ÎµÎ¼Î¯ÏƒÎµÎ¹ Ï„Î¿ output Î¼Îµ Captures/W0000."""
    with suppress_tf_io():                                # ÎºÏÏÏˆÎµ ÎµÏƒÏ‰Ï„ÎµÏÎ¹ÎºÎ¬ prints Ï„Î¿Ï… converter
        tfl = converter.convert()                         # ÎºÎ¬Î½ÎµÎ¹ compile Ï„Î¿ flatbuffer (.tflite) ÏƒÏ„Î· Î¼Î½Î®Î¼Î·
    with open(out_path, "wb") as f:                       # Î³ÏÎ¬Ï†ÎµÎ¹ ÏƒÎµ Î±ÏÏ‡ÎµÎ¯Î¿ Î´Ï…Î±Î´Î¹ÎºÎ¬
        f.write(tfl)

def print_tflite_io(path: str):
    """Î“ÏÎ®Î³Î¿ÏÎ¿, ÎºÎ±Î¸Î±ÏÏŒ summary Î³Î¹Î± ÏƒÏ‡Î®Î¼Î±Ï„Î±/Ï„ÏÏ€Î¿Ï…Ï‚ ÎµÎ¹ÏƒÏŒÎ´Î¿Ï…-ÎµÎ¾ÏŒÎ´Î¿Ï… ÎµÎ½ÏŒÏ‚ .tflite."""
    interp = tf.lite.Interpreter(model_path=path)         # Ï†Î¿ÏÏ„ÏÎ½ÎµÎ¹ interpreter
    interp.allocate_tensors()                             # ÎºÎ¬Î½ÎµÎ¹ allocate tensors
    ide = interp.get_input_details()[0]                   # 1 ÎµÎ¯ÏƒÎ¿Î´Î¿Ï‚: dict Î¼Îµ 'shape','dtype', ...
    ode = interp.get_output_details()[0]                  # 1 Î­Î¾Î¿Î´Î¿Ï‚
    print(f"ğŸ“¦ {os.path.basename(path)}")
    print(f"   input : shape {ide['shape']} dtype {ide['dtype']}")   # Ï€.Ï‡. [1 224 224 3], float32/int8
    print(f"   output: shape {ode['shape']} dtype {ode['dtype']}")   # Ï€.Ï‡. [1 5], float32/int8
# -------------------------------------------------------------------------


# ----------------------------- [PATHS / SPLIT] ----------------------------
ORIGINAL_DATASET = "/kaggle/input/trash-dataset/dataset"  # Î±ÏÏ‡Î¹ÎºÏŒ dataset (Ï†Î±ÎºÎµÎ»Î¿Î¹/ÎºÎ»Î¬ÏƒÎµÎ¹Ï‚)
SPLIT_DATASET    = "/kaggle/working/dataset_split"        # Ï€Î¿Ï Î¸Î± Î³ÏÎ±Ï†Ï„ÎµÎ¯ Ï„Î¿ split
OUT_DIR          = "/kaggle/working"                       # Î­Î¾Î¿Î´Î¿Î¹ (.keras, .tflite, labels.txt)

print("ğŸ“ ORIGINAL_DATASET contains:", os.listdir(ORIGINAL_DATASET))  # Î´ÎµÎ¯Î¾Îµ Ï„Î¹ Ï†Î±ÎºÎ­Î»Î¿Ï…Ï‚ Î­Ï‡ÎµÎ¹

# Î Î¿ÏƒÎ¿ÏƒÏ„Î¬ Î³Î¹Î± train/val/test
train_split, val_split, test_split = 0.70, 0.15, 0.15     # 70/15/15

# Î‘Î½ Ï…Ï€Î¬ÏÏ‡ÎµÎ¹ Î®Î´Î· Ï€Î±Î»Î¹ÏŒ split, ÎºÎ±Î¸Î¬ÏÎ¹ÏƒÎ­ Ï„Î¿ (Î³Î¹Î± Î½Î± Î¼Î·Î½ Î±Î½Î±Î¼ÎµÎ¹Ï‡Î¸Î¿ÏÎ½ Î±ÏÏ‡ÎµÎ¯Î±)
if os.path.exists(SPLIT_DATASET):
    shutil.rmtree(SPLIT_DATASET)                          # Î´Î¹Î±Î³ÏÎ±Ï†Î® Ï†Î±ÎºÎ­Î»Î¿Ï… Î±Î½Î±Î´ÏÎ¿Î¼Î¹ÎºÎ¬

# Î”Î·Î¼Î¹Î¿Ï…ÏÎ³Î¯Î± ÎºÎµÎ½ÏÎ½ Ï†Î±ÎºÎ­Î»Ï‰Î½ Ï€ÏÎ¿Î¿ÏÎ¹ÏƒÎ¼Î¿Ï Î³Î¹Î± ÎºÎ¬Î¸Îµ split ÎºÎ±Î¹ ÎºÎ¬Î¸Îµ ÎºÎ»Î¬ÏƒÎ·
for s in ['train','validation','test']:
    for c in os.listdir(ORIGINAL_DATASET):
        os.makedirs(os.path.join(SPLIT_DATASET, s, c), exist_ok=True)  # exist_ok: Î¼Î·Î½ ÏƒÎºÎ¬ÏƒÎµÎ¹Ï‚ Î±Î½ Ï…Ï€Î¬ÏÏ‡ÎµÎ¹

# Î ÏÎ±Î³Î¼Î±Ï„Î¹ÎºÎ® Î±Î½Ï„Î¹Î³ÏÎ±Ï†Î® ÎµÎ¹ÎºÏŒÎ½Ï‰Î½ Î¼Îµ shuffle
for c in os.listdir(ORIGINAL_DATASET):
    src = os.path.join(ORIGINAL_DATASET, c)
    if not os.path.isdir(src):            # Î±Î½ ÎµÎ¯Î½Î±Î¹ Î±ÏÏ‡ÎµÎ¯Î¿ ÎºÎ±Î¹ ÏŒÏ‡Î¹ Ï†Î¬ÎºÎµÎ»Î¿Ï‚, Î±Î³Î½ÏŒÎ·ÏƒÎ­ Ï„Î¿
        continue
    imgs = os.listdir(src); random.shuffle(imgs)          # Î±Î½Î±ÎºÎ¬Ï„ÎµÏˆÎµ Î»Î¯ÏƒÏ„Î± ÎµÎ¹ÎºÏŒÎ½Ï‰Î½
    n = len(imgs); a = int(train_split*n); b = a + int(val_split*n)  # indices ÎºÎ¿ÏˆÎ¯Î¼Î±Ï„Î¿Ï‚
    for i in imgs[:a]:
        shutil.copyfile(os.path.join(src, i), os.path.join(SPLIT_DATASET, "train", c, i))       # train copy
    for i in imgs[a:b]:
        shutil.copyfile(os.path.join(src, i), os.path.join(SPLIT_DATASET, "validation", c, i))  # val copy
    for i in imgs[b:]:
        shutil.copyfile(os.path.join(src, i), os.path.join(SPLIT_DATASET, "test", c, i))        # test copy

print("âœ… Split done.")
print("ğŸ“‚ Î¥Ï€Î¿Ï†Î¬ÎºÎµÎ»Î¿Î¹:", os.listdir(SPLIT_DATASET))        # Î±Î½Î±Î¼Î­Î½Î¿Ï…Î¼Îµ ['train','validation','test']
# -------------------------------------------------------------------------


# ----------------------------- [GENERATORS / AUGMENT] ---------------------
IMG_SIZE   = (224, 224)                   # Î¼Î­Î³ÎµÎ¸Î¿Ï‚ ÎµÎ¹ÏƒÏŒÎ´Î¿Ï… Ï€ÏÎ¿Ï‚ EfficientNetB0
BATCH_SIZE = 32                           # Ï€ÏŒÏƒÎ± Î´ÎµÎ¯Î³Î¼Î±Ï„Î± Î±Î½Î¬ batch
EPOCHS_STAGE1 = 8                         # ÎµÎºÏ€Î±Î¯Î´ÎµÏ…ÏƒÎ· "ÎºÎµÏ†Î±Î»Î®Ï‚"
EPOCHS_STAGE2 = 22                        # fine-tuning ÎºÎ¿ÏÎ¼Î¿Ï
FINE_TUNE_AT  = 60                        # Î±Ï€ÏŒ Ï€Î¿Î¹Î¿ layer index ÎºÎ±Î¹ Ï€Î¬Î½Ï‰ Î¸Î± Î¾ÎµÏ€Î±Î³ÏÏƒÎ¿Ï…Î¼Îµ

# Î£Ï…Î»Î»Î¿Î³Î® Î¿Î½Î¿Î¼Î¬Ï„Ï‰Î½ ÎºÎ»Î¬ÏƒÎµÏ‰Î½ Î±Ï€ÏŒ Ï„Î¿ split (Ï„Î±Î¾Î¹Î½Î¿Î¼Î·Î¼Î­Î½Î± Î³Î¹Î± ÏƒÏ„Î±Î¸ÎµÏÏŒ mapping)
CATEGORIES = sorted([
    c for c in os.listdir(os.path.join(SPLIT_DATASET, "train"))
    if os.path.isdir(os.path.join(SPLIT_DATASET, "train", c)) and not c.startswith("trash")
])
NUM_CLASSES = len(CATEGORIES)
print("ğŸ” Classes:", CATEGORIES)

# TRAIN: Î´Ï…Î½Î±Ï„Î¬ Î±Î»Î»Î¬ ÏÎµÎ±Î»Î¹ÏƒÏ„Î¹ÎºÎ¬ augmentations + ÏƒÏ‰ÏƒÏ„ÏŒ normalize Î³Î¹Î± EfficientNet
train_datagen = ImageDataGenerator(
    preprocessing_function=preprocess_input,   # ÎœÎ•Î“Î‘Î›Î— ÏƒÎ·Î¼Î±ÏƒÎ¯Î±: Î¯Î´Î¹Î¿ normalization Î¼Îµ Ï„Î¿ pretrain
    featurewise_center=False, samplewise_center=False,  # ÏƒÎ¹Î³Î® warnings
    rotation_range=25, width_shift_range=0.15, height_shift_range=0.15,
    zoom_range=0.25, shear_range=0.12, horizontal_flip=True,
    brightness_range=(0.75, 1.25), channel_shift_range=10.0,
    fill_mode='nearest'
)
# VAL/TEST: Î¼ÏŒÎ½Î¿ normalize (ÎºÎ±Î¼Î¯Î± Î±Î»Î»Î¿Î¯Ï‰ÏƒÎ·)
valtest_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)

# Î”Î·Î¼Î¹Î¿Ï…ÏÎ³Î¯Î± ÏÎ¿ÏÎ½ Î±Ï€ÏŒ Ï†Î±ÎºÎ­Î»Î¿Ï…Ï‚ (Keras Î¸Î± Ï†ÏÎ¿Î½Ï„Î¯ÏƒÎµÎ¹ Î½Î± ÎºÎ¬Î½ÎµÎ¹ on-the-fly augment/resize)
train_gen = train_datagen.flow_from_directory(
    os.path.join(SPLIT_DATASET, "train"),
    target_size=IMG_SIZE, batch_size=BATCH_SIZE,
    classes=CATEGORIES, class_mode='categorical', seed=SEED
)
val_gen = valtest_datagen.flow_from_directory(
    os.path.join(SPLIT_DATASET, "validation"),
    target_size=IMG_SIZE, batch_size=BATCH_SIZE,
    classes=CATEGORIES, class_mode='categorical', seed=SEED
)
test_gen = valtest_datagen.flow_from_directory(
    os.path.join(SPLIT_DATASET, "test"),
    target_size=IMG_SIZE, batch_size=BATCH_SIZE,
    classes=CATEGORIES, class_mode='categorical', shuffle=False  # shuffle=False Î³Î¹Î± ÏƒÏ‰ÏƒÏ„Î­Ï‚ Î¼ÎµÏ„ÏÎ¹ÎºÎ­Ï‚
)
# -------------------------------------------------------------------------


# ----------------------------- [CLASS WEIGHTS -> SAMPLE WEIGHT] -----------
# ÎœÎµÏ„ÏÎ¬Î¼Îµ Ï€ÏŒÏƒÎ± Î´ÎµÎ¯Î³Î¼Î±Ï„Î± Î­Ï‡ÎµÎ¹ ÎºÎ¬Î¸Îµ ÎºÎ»Î¬ÏƒÎ· ÏƒÏ„Î¿ TRAIN Î³Î¹Î± Î½Î± Î¶Ï…Î³Î¯ÏƒÎ¿Ï…Î¼Îµ ÏƒÏ‰ÏƒÏ„Î¬ Ï„Î· ÏƒÏ…Î½ÎµÎ¹ÏƒÏ†Î¿ÏÎ¬ Ï„Î¿Ï…Ï‚.
train_counts = np.bincount(train_gen.classes, minlength=NUM_CLASSES)  # Ï€Î»Î®Î¸Î¿Ï‚ Î±Î½Î¬ class id
tot = int(train_counts.sum())                                         # ÏƒÏÎ½Î¿Î»Î¿ Î´ÎµÎ¹Î³Î¼Î¬Ï„Ï‰Î½
raw = {i: float(tot/(NUM_CLASSES*max(1, c))) for i, c in enumerate(train_counts)}  # Î±Î½Ï„Î¹ÏƒÏ„ÏÏŒÏ†Ï‰Ï‚ Î±Î½Î¬Î»Î¿Î³Î±
class_weights = {i: float(np.clip(w, 0.7, 1.6)) for i, w in raw.items()}           # clip Î³Î¹Î± ÏƒÏ„Î±Î¸ÎµÏÏŒÏ„Î·Ï„Î±
print("ğŸ“Š Train counts:", dict(zip(CATEGORIES, train_counts.tolist())))
print("âš–ï¸ Class weights (clipped):", class_weights)

# Î˜Î± Ï‡ÏÎµÎ¹Î±ÏƒÏ„Î¿ÏÎ¼Îµ Î­Î½Î± vector [C] Î¼Îµ weights Î³Î¹Î± Î½Î± Î²Î³Î¬Î¶Î¿Ï…Î¼Îµ sample_weight ÏƒÎµ MixUp
weight_vec = np.array([class_weights[i] for i in range(NUM_CLASSES)], dtype=np.float32)
# -------------------------------------------------------------------------


# ----------------------------- [MIXUP GENERATOR] --------------------------
def mixup_same_batch_generator(gen, weight_vec, alpha=0.4):
    """
    Î Î±ÏÎ¬Î³ÎµÎ¹ Î¬Ï€ÎµÎ¹ÏÎ± batches MixUp Î±Ï€ÏŒ Î­Î½Î±Î½ ImageDataGenerator.
    Î•Ï€Î¹ÏƒÏ„ÏÎ­Ï†ÎµÎ¹ Ï„ÏÎ¹Î¬Î´Î± (x_mix, y_mix, sample_weight) ÏÏƒÏ„Îµ Ï„Î¿ model.fit Î½Î± Ï„Î·Î½ Î´ÎµÏ‡Ï„ÎµÎ¯ ÎºÎ±Î½Î¿Î½Î¹ÎºÎ¬.
    """
    while True:
        x, y = next(gen)                                # x: (B,H,W,3) float32, y: (B,C) one-hot
        B = x.shape[0]                                  # Î¼Î­Î³ÎµÎ¸Î¿Ï‚ batch (Î¼Ï€Î¿ÏÎµÎ¯ Î½Î± ÎµÎ¯Î½Î±Î¹ Î¼Î¹ÎºÏÏŒÏ„ÎµÏÎ¿ ÏƒÏ„Î¿ Ï„Î­Î»Î¿Ï‚)
        idx = np.random.permutation(B)                  # Ï„Ï…Ï‡Î±Î¯Î± Î±Î½Ï„Î¹ÏƒÏ„Î¿Î¯Ï‡Î¹ÏƒÎ· Î³Î¹Î± "Î¶ÎµÏ…Î³Î¬ÏÎ¹Î±" Î´ÎµÎ¹Î³Î¼Î¬Ï„Ï‰Î½
        lam = np.random.beta(alpha, alpha, size=(B,)).astype(np.float32)  # Î» ~ Beta(Î±,Î±)
        lam_x = lam.reshape(B, 1, 1, 1)                 # reshape Î³Î¹Î± broadcast ÏƒÎµ ÎµÎ¹ÎºÏŒÎ½ÎµÏ‚
        lam_y = lam.reshape(B, 1)                       # reshape Î³Î¹Î± broadcast ÏƒÎµ labels

        x2, y2 = x[idx], y[idx]                         # Ï„Î± shuffled "Î¶ÎµÏ…Î³Î¬ÏÎ¹Î±"
        x_mix = lam_x * x + (1.0 - lam_x) * x2         # MixUp ÎµÎ¹ÎºÏŒÎ½Ï‰Î½
        y_mix = lam_y * y + (1.0 - lam_y) * y2         # MixUp labels (soft labels)

        # sample_weight: Ï…Ï€Î¿Î»Î¿Î³Î¯Î¶Î¿Ï…Î¼Îµ Î²Î¬ÏÎ¿Ï‚ Î±Î½Î¬ Î´ÎµÎ¯Î³Î¼Î± -> (y_mix * class_weight).sum(axis=1)
        sw = (y_mix * weight_vec).sum(axis=1).astype(np.float32)  # shape: (B,)
        yield x_mix, y_mix, sw
# Î”Î·Î¼Î¹Î¿Ï…ÏÎ³Î¯Î± Ï„Î¿Ï… mixup generator
mix_gen = mixup_same_batch_generator(train_gen, weight_vec, alpha=0.4)
# -------------------------------------------------------------------------


# ----------------------------- [ÎœÎŸÎÎ¤Î•Î›ÎŸ] ----------------------------------
# EfficientNetB0 backbone (Ï€ÏÎ¿ÎµÎºÏ€Î±Î¹Î´ÎµÏ…Î¼Î­Î½Î¿ ÏƒÏ„Î¿ ImageNet) Ï‡Ï‰ÏÎ¯Ï‚ Ï„Î¿ top classifier
base = EfficientNetB0(weights='imagenet', include_top=False,
                      input_shape=(IMG_SIZE[0], IMG_SIZE[1], 3))
base.trainable = False                                   # Stage 1: Ï€Î±Î³Ï‰Î¼Î­Î½Î¿Ï‚ ÎºÎ¿ÏÎ¼ÏŒÏ‚

# Head: GAP -> Dropout -> Dense(192, swish, L2) -> Dense(NUM_CLASSES, softmax)
inp = layers.Input(shape=(IMG_SIZE[0], IMG_SIZE[1], 3))  # Î¿ÏÎ¹ÏƒÎ¼ÏŒÏ‚ input layer
x = base(inp, training=False)                            # training=False Î³Î¹Î± ÏƒÏ‰ÏƒÏ„ÏŒ BN behavior ÏƒÏ„Î¿ frozen
x = layers.GlobalAveragePooling2D()(x)                   # ÏƒÏ…Î¼Ï€ÏÎºÎ½Ï‰ÏƒÎ· Ï‡Ï‰ÏÎ¹ÎºÏÎ½ Î´Î¹Î±ÏƒÏ„Î¬ÏƒÎµÏ‰Î½
x = layers.Dropout(0.35)(x)                              # Ï„Î±ÎºÏ„Î¹ÎºÎ® regularization
x = layers.Dense(192, activation='swish',
                 kernel_regularizer=regularizers.l2(1e-5))(x)  # Î¼Î¹ÎºÏÏŒ L2 Î³Î¹Î± ÏƒÏ„Î±Î¸ÎµÏÏŒÏ„Î·Ï„Î±
out = layers.Dense(NUM_CLASSES, activation='softmax')(x) # logits -> Ï€Î¹Î¸Î±Î½ÏŒÏ„Î·Ï„ÎµÏ‚ ÎºÎ»Î¬ÏƒÎµÏ‰Î½
model = models.Model(inp, out)                           # Model(inputs, outputs)
model.summary()                                          # ÎµÎºÏ„ÏÏ€Ï‰ÏƒÎ· ÏƒÏÎ½Î¿ÏˆÎ·Ï‚ Î´Î¹ÎºÏ„ÏÎ¿Ï…
# -------------------------------------------------------------------------


# ----------------------------- [TRAINING â€” STAGE 1] -----------------------
steps_per_epoch = len(train_gen)                         # Ï€ÏŒÏƒÎ± batches/epoch Î±Ï€ÏŒ Ï„Î¿Î½ generator
total_steps = (EPOCHS_STAGE1 + EPOCHS_STAGE2) * steps_per_epoch  # Î³Î¹Î± Ï„Î¿ cosine decay
cosine = tf.keras.optimizers.schedules.CosineDecay(
    initial_learning_rate=1e-3,                         # Î±ÏÏ‡Î¹ÎºÏŒ LR
    decay_steps=total_steps                             # Ï€ÏŒÏƒÎ± Î²Î®Î¼Î±Ï„Î± Î¼Î­Ï‡ÏÎ¹ Ï„Î¿ minimum
)

model.compile(
    optimizer=tf.keras.optimizers.Adam(learning_rate=cosine),  # Adam Î¼Îµ cosine schedule
    loss=tf.keras.losses.CategoricalCrossentropy(label_smoothing=0.05),  # label smoothing Î³Î¹Î± Î³ÎµÎ½Î¯ÎºÎµÏ…ÏƒÎ·
    metrics=['accuracy']                                       # accuracy ÏƒÏ„Î¿ train/val
)

ckpt1 = os.path.join(OUT_DIR, "best_effb0_stage1.keras")       # Î´Î¹Î±Î´ÏÎ¿Î¼Î® best Î¼Î¿Î½Ï„Î­Î»Î¿Ï… stage1
cbs1 = [
    ReduceLROnPlateau(monitor='val_loss', factor=0.4, patience=2, verbose=1),  # Î±Î½ "ÎºÎ¿Î»Î»Î®ÏƒÎµÎ¹", ÏÎ¯Î¾Îµ LR
    EarlyStopping(monitor='val_loss', patience=4, restore_best_weights=True, verbose=1),  # ÏƒÏ„Î±Î¼Î¬Ï„Î± Î½Ï‰ÏÎ¯Ï‚
    ModelCheckpoint(ckpt1, monitor='val_loss', save_best_only=True, verbose=1)  # ÎºÏÎ¬Ï„Î± Ï„Î¿ ÎºÎ±Î»ÏÏ„ÎµÏÎ¿
]

history1 = model.fit(
    mix_gen,                                                   # (x, y, sample_weight) Î±Ï€ÏŒ MixUp
    steps_per_epoch=steps_per_epoch,
    epochs=EPOCHS_STAGE1,
    validation_data=val_gen,                                   # val Ï‡Ï‰ÏÎ¯Ï‚ MixUp
    callbacks=cbs1,
    verbose=1
)

# Ï†ÏŒÏÏ„Ï‰ÏƒÎµ Ï„Î± ÎºÎ±Î»ÏÏ„ÎµÏÎ± weights Ï„Î¿Ï… stage1 (ÏƒÏÎ¼Ï†Ï‰Î½Î± Î¼Îµ val_loss)
if os.path.exists(ckpt1):
    model = tf.keras.models.load_model(ckpt1)
# -------------------------------------------------------------------------


# ----------------------------- [TRAINING â€” STAGE 2] -----------------------
# Unfreeze backbone ÎœÎ•Î¡Î™ÎšÎ‘ layers: Î±Ï€ÏŒ FINE_TUNE_AT ÎºÎ±Î¹ Ï€Î¬Î½Ï‰
base.trainable = True
for i, layer in enumerate(base.layers):
    layer.trainable = (i >= FINE_TUNE_AT)                      # True Î¼ÏŒÎ½Î¿ ÏƒÏ„Î± "Ï„ÎµÎ»ÎµÏ…Ï„Î±Î¯Î±" layers

model.compile(
    optimizer=tf.keras.optimizers.Adam(1e-5),                  # Ï€Î¿Î»Ï Î¼Î¹ÎºÏÏŒ LR Î³Î¹Î± fine-tune
    loss=tf.keras.losses.CategoricalCrossentropy(label_smoothing=0.05),
    metrics=['accuracy']
)

ckpt2 = os.path.join(OUT_DIR, "best_effb0_stage2.keras")
cbs2 = [
    ReduceLROnPlateau(monitor='val_loss', factor=0.4, patience=3, verbose=1),
    EarlyStopping(monitor='val_loss', patience=6, restore_best_weights=True, verbose=1),
    ModelCheckpoint(ckpt2, monitor='val_loss', save_best_only=True, verbose=1)
]

history2 = model.fit(
    mix_gen,
    steps_per_epoch=steps_per_epoch,
    epochs=EPOCHS_STAGE2,
    validation_data=val_gen,
    callbacks=cbs2,
    verbose=1
)

if os.path.exists(ckpt2):
    model = tf.keras.models.load_model(ckpt2)                 # Ï†ÏŒÏÏ„Ï‰ÏƒÎµ Ï„Î¿ ÎºÎ±Î»ÏÏ„ÎµÏÎ¿ Ï„Î¿Ï… stage2
# -------------------------------------------------------------------------


# ----------------------------- [EVALUATION â€” TTA] -------------------------
def predict_tta(model, generator, tta_times=5):
    """
    Î‘Ï€Î»ÏŒ TTA: 5 Ï€ÎµÏÎ¬ÏƒÎ¼Î±Ï„Î±, ÏƒÏ„Î± Î¼Î¿Î½Î¬ t ÎµÏ†Î±ÏÎ¼ÏŒÎ¶Î¿Ï…Î¼Îµ horizontal flip.
    ÎœÎ±Î¶ÎµÏÎ¿Ï…Î¼Îµ Ï€ÏÎ¿Î²Î»Î­ÏˆÎµÎ¹Ï‚ ÎºÎ±Î¹ ÎµÏ€Î¹ÏƒÏ„ÏÎ­Ï†Î¿Ï…Î¼Îµ Ï„Î¿Î½ Î¼Î­ÏƒÎ¿ ÏŒÏÎ¿.
    """
    preds = []
    for t in range(tta_times):
        generator.reset()                                      # ÎµÏ€Î±Î½ÎµÎºÎºÎ¯Î½Î·ÏƒÎ· generator Î³Î¹Î± ÏƒÏ…Î½ÎµÏ€Î® batches
        batch_preds = []
        for _ in range(len(generator)):                         # Ï„ÏŒÏƒÎ± Î²Î®Î¼Î±Ï„Î± ÏŒÏƒÎ± batches Î­Ï‡ÎµÎ¹ Ï„Î¿ generator
            x, _ = next(generator)                              # Ï€Î±Î¯ÏÎ½Î¿Ï…Î¼Îµ ÎµÎ¹ÎºÏŒÎ½ÎµÏ‚ (labels Î´Îµ Ï‡ÏÎµÎ¹Î¬Î¶Î¿Î½Ï„Î±Î¹)
            if t % 2 == 1:
                x = x[:, :, ::-1, :]                           # Î¿ÏÎ¹Î¶ÏŒÎ½Ï„Î¹Î¿ flip (W axis Î±Î½Ï„Î¹ÏƒÏ„ÏÎ­Ï†ÎµÏ„Î±Î¹)
            p = model.predict(x, verbose=0)                     # Ï€ÏÎ¿Î²Î»Î­ÏˆÎµÎ¹Ï‚ (B, C)
            batch_preds.append(p)
        preds.append(np.vstack(batch_preds))                    # (N, C)
    return np.mean(preds, axis=0)                               # Î¼Î­ÏƒÎ¿Ï‚ ÏŒÏÎ¿Ï‚ Ï€Î¬Î½Ï‰ ÏƒÏ„Î± tta passes -> (N, C)

test_probs = predict_tta(model, test_gen, tta_times=5)          # Ï€Î¹Î¸Î±Î½ÏŒÏ„Î·Ï„ÎµÏ‚ Î³Î¹Î± ÎŸÎ›ÎŸ Ï„Î¿ test set
y_pred = np.argmax(test_probs, axis=1)                          # predicted class id
y_true = test_gen.classes                                       # ground truth ids (Î±Ï€ÏŒ generator)

test_acc = (y_pred == y_true).mean()                            # accuracy
print(f"\nâœ… Test Accuracy (TTA): {test_acc:.4f}")
# -------------------------------------------------------------------------


# ----------------------------- [PLOTS / REPORTS] --------------------------
def plot_hist(h1, h2):
    """Î•Î½Î¹Î±Î¯Î¿ plot Î³Î¹Î± train/val accuracy (stage1+stage2)."""
    acc = h1.history['accuracy'] + h2.history['accuracy']      # Î»Î¯ÏƒÏ„ÎµÏ‚ ÎµÏ€Î¿Ï‡ÏÎ½ ÎºÎ¿Î»Î»Î·Î¼Î­Î½ÎµÏ‚
    val = h1.history['val_accuracy'] + h2.history['val_accuracy']
    plt.figure(figsize=(6, 4))
    plt.plot(acc, label='Train'); plt.plot(val, label='Val')
    plt.title("EfficientNetB0 â€” Training & Validation")
    plt.xlabel("Epochs"); plt.ylabel("Accuracy")
    plt.grid(True); plt.legend(); plt.show()

plot_hist(history1, history2)

labels = list(test_gen.class_indices.keys())                    # mapping id->ÏŒÎ½Î¿Î¼Î± ÎºÎ»Î¬ÏƒÎ·Ï‚
print("\nğŸ“„ Classification Report:")
print(classification_report(y_true, y_pred, target_names=labels))          # precision/recall/f1 Î±Î½Î¬ ÎºÎ»Î¬ÏƒÎ·
print("ğŸ”¢ Weighted F1:", f1_score(y_true, y_pred, average='weighted'))     # ÏƒÏ„Î±Î¸Î¼Î¹ÏƒÎ¼Î­Î½Î¿ F1

cm = confusion_matrix(y_true, y_pred)                           # Ï€Î¹Î½. ÏƒÏÎ³Ï‡Ï…ÏƒÎ·Ï‚
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)
disp.plot(cmap=plt.cm.Blues, xticks_rotation=45)
plt.title("ğŸ“Š Confusion Matrix"); plt.grid(False); plt.show()
# -------------------------------------------------------------------------


# ----------------------------- [SAVE MODEL & LABELS] ----------------------
model_path = os.path.join(OUT_DIR, "model_effb0_mixup.keras")
with suppress_tf_io():                                          # ÎºÏŒÎ²ÎµÎ¹ verbose "Captures" Î±Ï€ÏŒ SavedModel
    model.save(model_path, include_optimizer=False)             # ÏƒÏÎ¶Î¿Ï…Î¼Îµ Ï‡Ï‰ÏÎ¯Ï‚ optimizer (Ï€Î¹Î¿ Î¼Î¹ÎºÏÏŒ)
print("ğŸ’¾ Saved:", model_path)

with open(os.path.join(OUT_DIR, "labels.txt"), "w") as f:       # ÏƒÏÎ¶Ï‰ labels (Î¼Î¯Î± Î±Î½Î¬ Î³ÏÎ±Î¼Î¼Î®)
    for lb in labels:
        f.write(lb + "\n")
# -------------------------------------------------------------------------


# ----------------------------- [TFLITE EXPORTS] --------------------------
# (Î±) FP16: Ï€Î¿Î»Ï ÎºÎ±Î»Î® Î¹ÏƒÎ¿ÏÏÎ¿Ï€Î¯Î± Î±ÎºÏÎ¯Î²ÎµÎ¹Î±Ï‚/Î¼Î­Î³ÎµÎ¸Î¿Ï‚/Ï„Î±Ï‡ÏÏ„Î·Ï„Î± ÏƒÎµ Ï€Î¿Î». ÏƒÏ…ÏƒÎºÎµÏ…Î­Ï‚
fp16_path = os.path.join(OUT_DIR, "model_effb0_mixup_fp16.tflite")
conv = tf.lite.TFLiteConverter.from_keras_model(model)          # converter Î±Ï€ÏŒ keras model
conv.optimizations = [tf.lite.Optimize.DEFAULT]                 # ÎµÎ½ÎµÏÎ³Î¿Ï€Î¿Î¯Î·ÏƒÎ· default optimizations
conv.target_spec.supported_types = [tf.float16]                 # FP16 Î²Î¬ÏÎ·/Ï…Ï€Î¿Î»Î¿Î³Î¹ÏƒÎ¼Î¿Î¯
save_tflite_quiet(conv, fp16_path)                              # ÏƒÎ¹Ï‰Ï€Î·Î»Î¬
print_tflite_io(fp16_path)                                      # ÎºÎ±Î¸Î±ÏÏŒ summary Î™/ÎŸ

# (Î²) INT8 (Ï€ÏÎ¿Î±Î¹ÏÎµÏ„Î¹ÎºÏŒ): Î¼Î¹ÎºÏÏŒÏ„ÎµÏÎ¿/Î³ÏÎ·Î³Î¿ÏÏŒÏ„ÎµÏÎ¿. Î˜Î­Î»ÎµÎ¹ representative dataset Î³Î¹Î± calibration.
def rep_gen():
    files = []
    for c in labels:
        files += glob.glob(os.path.join(SPLIT_DATASET, "train", c, "*"))[:60]  # ~60 ÎµÎ¹ÎºÏŒÎ½ÎµÏ‚/ÎºÎ»Î¬ÏƒÎ·
    for fp in files:
        im = Image.open(fp).convert("RGB").resize(IMG_SIZE, Image.BILINEAR)    # resize HxW
        arr = np.array(im).astype(np.float32)                                  # ÏƒÎµ float32
        arr = preprocess_input(arr)                                            # Î Î‘ÎÎ¤Î‘ Î¯Î´Î¹Î¿ preprocessing
        yield [np.expand_dims(arr, 0)]                                         # batch=1, shape (1,H,W,3)

int8_path = os.path.join(OUT_DIR, "model_effb0_mixup_int8.tflite")
try:
    conv_i8 = tf.lite.TFLiteConverter.from_keras_model(model)
    conv_i8.optimizations = [tf.lite.Optimize.DEFAULT]                          # ÎµÎ½ÎµÏÎ³Î¿Ï€Î¿Î¯Î·ÏƒÎ· quantization pass
    conv_i8.representative_dataset = rep_gen                                    # calibration samples
    conv_i8.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]   # ÎºÎ±Î¸Î±ÏÏŒ INT8 graph
    conv_i8.inference_input_type = tf.int8                                      # ÎµÎ¯ÏƒÎ¿Î´Î¿Ï‚ INT8
    conv_i8.inference_output_type = tf.int8                                     # Î­Î¾Î¿Î´Î¿Ï‚ INT8
    save_tflite_quiet(conv_i8, int8_path)                                       # ÏƒÎ¹Ï‰Ï€Î·Î»Î¬
    print_tflite_io(int8_path)
except Exception as e:
    print("âš ï¸ INT8 conversion skipped:", e)                                     # Ï€.Ï‡. Î±Î½ Î»ÎµÎ¯Ï€Î¿Ï…Î½ ops
# --------------------------------------------------------------------------



# ============================================
# ONNX CONVERSION (Î³Î¹Î± Java backend)
# ============================================

print("\nğŸ”„ Converting model to ONNX format...")

# 1) Install tf2onnx (Kaggle Î´ÎµÎ½ Ï„Î¿ Î­Ï‡ÎµÎ¹ by default)
import subprocess
subprocess.run(["pip", "install", "-q", "tf2onnx", "onnx"], check=True)

import tf2onnx
import onnx

# 2) Load Ï„Î¿ Keras model Ï€Î¿Ï… Î¼ÏŒÎ»Î¹Ï‚ ÏƒÏÏƒÎ±Î¼Îµ
model_for_onnx = tf.keras.models.load_model(model_path)

# 3) Define input signature (224x224x3 RGB image)
spec = (tf.TensorSpec((None, 224, 224, 3), tf.float32, name="input"),)

# 4) Convert ÏƒÎµ ONNX
onnx_path = os.path.join(OUT_DIR, "model_effb0_mixup.onnx")

model_proto, _ = tf2onnx.convert.from_keras(
    model_for_onnx,
    input_signature=spec,
    opset=13,  # ONNX opset version
    output_path=onnx_path
)

print(f"âœ… ONNX model saved: {onnx_path}")

# 5) Verify Ï„Î¿ ONNX model
onnx_model = onnx.load(onnx_path)
onnx.checker.check_model(onnx_model)
print("âœ… ONNX model verified successfully!")

# 6) Print ONNX model info
import onnxruntime as ort
session = ort.InferenceSession(onnx_path)
input_info = session.get_inputs()[0]
output_info = session.get_outputs()[0]

print("\nğŸ“¦ ONNX Model Info:")
print(f"   Input : {input_info.name} | shape: {input_info.shape} | type: {input_info.type}")
print(f"   Output: {output_info.name} | shape: {output_info.shape} | type: {output_info.type}")